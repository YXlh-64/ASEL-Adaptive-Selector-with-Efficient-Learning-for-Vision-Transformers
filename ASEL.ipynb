{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccaa206",
   "metadata": {},
   "source": [
    "# ASEL Pipeline: Main Process Overview\n",
    "\n",
    "This notebook implements **ASEL**, a ViT-based model with a learned patch selector for efficient inference on CIFAR‑10 and remote‑sensing datasets (AID, EuroSAT, RSSCN7). The pipeline in this notebook has **two concrete phases**, with caching and benchmarking built in.\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1 – CIFAR‑10 Warmup\n",
    "\n",
    "1. **Model and Selector**\n",
    "   - Backbone: `vit_tiny_patch16_224` from `timm` (classification head + transformer blocks).\n",
    "   - Selector: a small MLP (`patch_selector`) that takes each patch embedding concatenated with a global feature and outputs an importance score per patch.\n",
    "\n",
    "2. **Training Setup on CIFAR‑10**\n",
    "   - Dataset: CIFAR‑10 loaded via `get_dataset('cifar10')`, with a single train/test split (no validation).\n",
    "   - Checkpoint path: `./saved_models/cifar10_warmup.pth`.\n",
    "   - If this file **exists**, it is loaded and **training on CIFAR‑10 is skipped**.\n",
    "   - If it does **not** exist:\n",
    "     - A new `ASEL(num_classes=10)` model is trained for **15 epochs** using `train_epoch`.\n",
    "     - Dynamic keep‑ratio inside `train_epoch`:\n",
    "       - For epochs `< 5`: `k_ratio = 1.0` (all patches kept).\n",
    "       - For epochs `≥ 5`: `k_ratio` is sampled uniformly in `[0.15, 0.75]` for each batch.\n",
    "     - Loss per batch:\n",
    "       - `loss_cls = cross_entropy(logits, labels)`\n",
    "       - `loss_sparsity = 0.02 * scores.mean()`\n",
    "       - `loss = loss_cls + loss_sparsity`.\n",
    "     - Optimizer during warmup:\n",
    "       - `patch_selector` parameters: lr = `CONFIG['learning_rate_selector']` (1e‑4).\n",
    "       - Backbone parameters (excluding head): lr = 5e‑5.\n",
    "       - Classification head parameters: lr = 5e‑4.\n",
    "     - After training, the model weights are saved to `cifar10_warmup.pth`.\n",
    "\n",
    "3. **CIFAR‑10 Benchmarks**\n",
    "   - Regardless of whether the model was loaded or trained, `run()` always:\n",
    "     - Builds a deterministic test DataLoader using `create_loader(cifar_te, batch_size, shuffle=False)`.\n",
    "     - Calls `run_benchmarks_and_plot(model, loader_te, 'cifar10', device)`.\n",
    "   - `run_benchmarks_and_plot` evaluates ASEL at keep‑ratios `[0.1, 0.2, ..., 1.0]` for three policies in `forward_inference`:\n",
    "     - `learned`: top‑k patches by selector scores.\n",
    "     - `random`: random subset of patches with the same budget.\n",
    "     - `central`: most central patches in the 14×14 patch grid.\n",
    "   - For each ratio, it records: accuracy (per policy), GFLOPs, batch latency, and throughput via the `Benchmark` class.\n",
    "   - Plots are saved in `CONFIG['results_path']` (`./benchmarks_results`) with names:\n",
    "     - `{ds_name}_1_strategies.png` (accuracy vs keep‑ratio for learned/random/central + full ViT).\n",
    "     - `{ds_name}_2_throughput.png` (accuracy vs throughput).\n",
    "     - `{ds_name}_3_gflops.png` (GFLOPs vs keep‑ratio).\n",
    "     - `{ds_name}_4_latency.png` (latency bar: full ViT vs 50% keep).\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 2 – Transfer to Remote‑Sensing Datasets\n",
    "\n",
    "4. **Target Datasets and Splits**\n",
    "   - Targets: `['aid', 'eurosat', 'rsscn7']`.\n",
    "   - `get_dataset(name)` uses:\n",
    "     - For `'eurosat'`: torchvision `EuroSAT` with an **80/20 train/val split** using a fixed generator `GEN`.\n",
    "     - For `'aid'`, `'ucmerced'`, `'rsscn7'`:\n",
    "       - Image folders read via `CleanImageFolder` (ignores hidden folders).\n",
    "       - **80/20 train/test split** using `random_split(..., generator=GEN)` for deterministic behavior.\n",
    "   - `create_loader` builds DataLoaders with:\n",
    "     - `worker_init_fn=seed_worker` for reproducible workers.\n",
    "     - `generator=GEN` when `shuffle=True` to keep shuffling deterministic.\n",
    "\n",
    "5. **Transfer Learning from CIFAR‑10**\n",
    "   - For each dataset `ds_name` in `['aid', 'eurosat', 'rsscn7']`, `run()` does:\n",
    "     - Builds `save_name = ./saved_models/{ds_name}_finetuned.pth`.\n",
    "     - Creates a fresh `ASEL(num_classes=n_cls)` model on the configured device.\n",
    "     - If `save_name` exists:\n",
    "       - Loads `model_transfer.load_state_dict(torch.load(save_name))`.\n",
    "       - **Skips all further training** for that dataset.\n",
    "     - Otherwise (no saved model):\n",
    "       - Loads CIFAR‑10 warmup weights from `cifar10_warmup.pth`.\n",
    "       - Removes all head weights from the CIFAR‑10 state dict (`'head' not in k`) so the target dataset gets a new classification head.\n",
    "       - Updates `model_transfer.state_dict()` with the non‑head weights and loads them.\n",
    "       - Builds a train loader for the target dataset with `create_loader(train_ds, shuffle=True)`.\n",
    "       - Trains for **25 epochs** using `train_epoch` with the same dynamic k‑ratio schedule and loss structure as in warmup.\n",
    "       - Optimizer for transfer:\n",
    "         - `patch_selector`: lr = `CONFIG['learning_rate_selector']` (1e‑4).\n",
    "         - Backbone (excluding head): lr = 2e‑5.\n",
    "         - New classification head: lr = 5e‑4.\n",
    "       - Saves the fine‑tuned model to `./saved_models/{ds_name}_finetuned.pth`.\n",
    "\n",
    "6. **Benchmarks on Target Datasets**\n",
    "   - For **every** target dataset (loaded or newly trained), `run()` always:\n",
    "     - Creates a non‑shuffled test loader with `create_loader(test_ds, shuffle=False)`.\n",
    "     - Calls `run_benchmarks_and_plot(model_transfer, test_loader, ds_name, device)`.\n",
    "   - The same keep‑ratio grid, selector policies, and metrics as in CIFAR‑10 are used, and the plots are written to `./benchmarks_results` with filenames based on `ds_name`.\n",
    "\n",
    "---\n",
    "\n",
    "## Reproducibility Notes\n",
    "\n",
    "- `set_seed(CONFIG['seed'])` sets seeds for Python, NumPy, and all PyTorch/CUDA RNGs and configures CuDNN for deterministic behavior.\n",
    "- `GEN` (a `torch.Generator`) and `seed_worker` are used consistently in `random_split` and DataLoaders so that dataset splits and shuffling are repeatable across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PHASE 1: WARMUP ON CIFAR-10\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayane/maria-project/asal/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> No checkpoint found. Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep 0: 100%|██████████| 782/782 [00:25<00:00, 30.61it/s, Loss=0.2102, Acc=94.41%]\n",
      "Train Ep 1: 100%|██████████| 782/782 [00:25<00:00, 30.53it/s, Loss=0.0308, Acc=98.19%]\n",
      "Train Ep 2: 100%|██████████| 782/782 [00:25<00:00, 30.35it/s, Loss=0.0185, Acc=98.86%]\n",
      "Train Ep 3: 100%|██████████| 782/782 [00:25<00:00, 30.50it/s, Loss=0.0010, Acc=98.93%]\n",
      "Train Ep 4: 100%|██████████| 782/782 [00:25<00:00, 30.42it/s, Loss=0.0007, Acc=99.17%]\n",
      "Train Ep 5: 100%|██████████| 782/782 [00:25<00:00, 30.48it/s, Loss=0.0314, Acc=89.65%]\n",
      "Train Ep 6: 100%|██████████| 782/782 [00:25<00:00, 30.68it/s, Loss=0.0053, Acc=94.28%]\n",
      "Train Ep 7: 100%|██████████| 782/782 [00:25<00:00, 30.43it/s, Loss=0.0008, Acc=94.87%]\n",
      "Train Ep 8: 100%|██████████| 782/782 [00:25<00:00, 30.60it/s, Loss=0.2544, Acc=96.18%]\n",
      "Train Ep 9: 100%|██████████| 782/782 [00:25<00:00, 30.24it/s, Loss=0.0174, Acc=96.22%]\n",
      "Train Ep 10: 100%|██████████| 782/782 [00:25<00:00, 30.74it/s, Loss=0.9254, Acc=96.97%]\n",
      "Train Ep 11: 100%|██████████| 782/782 [00:25<00:00, 30.67it/s, Loss=0.0006, Acc=96.90%]\n",
      "Train Ep 12: 100%|██████████| 782/782 [00:25<00:00, 30.40it/s, Loss=0.0123, Acc=97.20%]\n",
      "Train Ep 13: 100%|██████████| 782/782 [00:25<00:00, 30.62it/s, Loss=0.0092, Acc=97.45%]\n",
      "Train Ep 14: 100%|██████████| 782/782 [00:25<00:00, 30.62it/s, Loss=0.0234, Acc=97.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training finished. Model saved.\n",
      "\n",
      "Running Benchmarks for cifar10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.1 | L-Acc: 72.9% | R-Acc: 65.9% | FPS: 37605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.2 | L-Acc: 86.4% | R-Acc: 82.2% | FPS: 30053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.3 | L-Acc: 90.9% | R-Acc: 89.0% | FPS: 26506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.4 | L-Acc: 93.2% | R-Acc: 92.2% | FPS: 21197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.5 | L-Acc: 94.7% | R-Acc: 94.0% | FPS: 19906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.6 | L-Acc: 95.8% | R-Acc: 95.3% | FPS: 16715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.7 | L-Acc: 96.4% | R-Acc: 95.9% | FPS: 13930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.8 | L-Acc: 96.7% | R-Acc: 96.5% | FPS: 13356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.9 | L-Acc: 97.0% | R-Acc: 96.7% | FPS: 10854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 1.0 | L-Acc: 97.1% | R-Acc: 97.1% | FPS: 9944\n",
      "\n",
      "========================================\n",
      "PHASE 2: TRANSFER TO AID\n",
      "========================================\n",
      ">> No checkpoint found for aid. Training...\n",
      ">> Loaded CIFAR-10 weights (Head re-initialized)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep 0: 100%|██████████| 125/125 [00:08<00:00, 14.57it/s, Loss=0.3077, Acc=69.95%]\n",
      "Train Ep 1: 100%|██████████| 125/125 [00:08<00:00, 14.52it/s, Loss=0.2954, Acc=93.64%]\n",
      "Train Ep 2: 100%|██████████| 125/125 [00:08<00:00, 14.41it/s, Loss=0.0865, Acc=97.81%]\n",
      "Train Ep 3: 100%|██████████| 125/125 [00:08<00:00, 14.00it/s, Loss=0.0258, Acc=99.39%]\n",
      "Train Ep 4: 100%|██████████| 125/125 [00:08<00:00, 14.27it/s, Loss=0.0107, Acc=99.91%]\n",
      "Train Ep 5: 100%|██████████| 125/125 [00:08<00:00, 14.62it/s, Loss=0.2232, Acc=89.45%]\n",
      "Train Ep 6: 100%|██████████| 125/125 [00:08<00:00, 14.47it/s, Loss=0.4249, Acc=93.96%]\n",
      "Train Ep 7: 100%|██████████| 125/125 [00:08<00:00, 14.50it/s, Loss=0.6277, Acc=95.05%]\n",
      "Train Ep 8: 100%|██████████| 125/125 [00:08<00:00, 14.06it/s, Loss=0.0723, Acc=97.00%]\n",
      "Train Ep 9: 100%|██████████| 125/125 [00:08<00:00, 14.24it/s, Loss=0.0209, Acc=97.59%]\n",
      "Train Ep 10: 100%|██████████| 125/125 [00:08<00:00, 14.52it/s, Loss=0.0271, Acc=97.72%]\n",
      "Train Ep 11: 100%|██████████| 125/125 [00:08<00:00, 14.08it/s, Loss=0.1131, Acc=98.86%]\n",
      "Train Ep 12: 100%|██████████| 125/125 [00:08<00:00, 14.56it/s, Loss=0.1251, Acc=98.81%]\n",
      "Train Ep 13: 100%|██████████| 125/125 [00:08<00:00, 14.55it/s, Loss=0.0068, Acc=99.09%]\n",
      "Train Ep 14: 100%|██████████| 125/125 [00:08<00:00, 14.22it/s, Loss=0.0421, Acc=99.51%]\n",
      "Train Ep 15: 100%|██████████| 125/125 [00:08<00:00, 14.04it/s, Loss=0.0090, Acc=99.09%]\n",
      "Train Ep 16: 100%|██████████| 125/125 [00:08<00:00, 14.48it/s, Loss=0.0027, Acc=99.12%]\n",
      "Train Ep 17: 100%|██████████| 125/125 [00:08<00:00, 14.49it/s, Loss=0.1814, Acc=98.94%]\n",
      "Train Ep 18: 100%|██████████| 125/125 [00:08<00:00, 14.56it/s, Loss=0.0036, Acc=99.45%]\n",
      "Train Ep 19: 100%|██████████| 125/125 [00:08<00:00, 14.15it/s, Loss=0.0034, Acc=99.38%]\n",
      "Train Ep 20: 100%|██████████| 125/125 [00:08<00:00, 14.55it/s, Loss=0.0019, Acc=99.49%]\n",
      "Train Ep 21: 100%|██████████| 125/125 [00:08<00:00, 14.10it/s, Loss=0.0028, Acc=99.58%]\n",
      "Train Ep 22: 100%|██████████| 125/125 [00:08<00:00, 14.26it/s, Loss=0.0080, Acc=99.30%]\n",
      "Train Ep 23: 100%|██████████| 125/125 [00:08<00:00, 14.55it/s, Loss=0.0121, Acc=99.70%]\n",
      "Train Ep 24: 100%|██████████| 125/125 [00:08<00:00, 14.52it/s, Loss=0.0914, Acc=99.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training finished for aid. Model saved.\n",
      "\n",
      "Running Benchmarks for aid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.1 | L-Acc: 64.3% | R-Acc: 55.9% | FPS: 37538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.2 | L-Acc: 79.7% | R-Acc: 72.7% | FPS: 30023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.3 | L-Acc: 86.8% | R-Acc: 80.1% | FPS: 26697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.4 | L-Acc: 89.8% | R-Acc: 85.3% | FPS: 21242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.5 | L-Acc: 91.8% | R-Acc: 87.6% | FPS: 19943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.6 | L-Acc: 92.8% | R-Acc: 89.5% | FPS: 16771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.7 | L-Acc: 93.2% | R-Acc: 89.8% | FPS: 14007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.8 | L-Acc: 93.5% | R-Acc: 91.4% | FPS: 13457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.9 | L-Acc: 93.1% | R-Acc: 91.7% | FPS: 10882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 1.0 | L-Acc: 92.3% | R-Acc: 92.3% | FPS: 9994\n",
      "Finished aid. Plots saved.\n",
      "\n",
      "========================================\n",
      "PHASE 2: TRANSFER TO EUROSAT\n",
      "========================================\n",
      ">> No checkpoint found for eurosat. Training...\n",
      ">> Loaded CIFAR-10 weights (Head re-initialized)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep 0: 100%|██████████| 338/338 [00:11<00:00, 30.67it/s, Loss=0.0413, Acc=92.54%]\n",
      "Train Ep 1: 100%|██████████| 338/338 [00:11<00:00, 30.56it/s, Loss=0.0049, Acc=98.42%]\n",
      "Train Ep 2: 100%|██████████| 338/338 [00:11<00:00, 30.50it/s, Loss=0.0060, Acc=99.35%]\n",
      "Train Ep 3: 100%|██████████| 338/338 [00:11<00:00, 30.46it/s, Loss=0.0869, Acc=99.59%]\n",
      "Train Ep 4: 100%|██████████| 338/338 [00:11<00:00, 30.53it/s, Loss=0.0016, Acc=99.90%]\n",
      "Train Ep 5: 100%|██████████| 338/338 [00:11<00:00, 30.21it/s, Loss=0.2111, Acc=96.00%]\n",
      "Train Ep 6: 100%|██████████| 338/338 [00:11<00:00, 30.71it/s, Loss=0.0309, Acc=97.44%]\n",
      "Train Ep 7: 100%|██████████| 338/338 [00:11<00:00, 30.59it/s, Loss=0.0007, Acc=98.00%]\n",
      "Train Ep 8: 100%|██████████| 338/338 [00:11<00:00, 30.47it/s, Loss=0.0020, Acc=98.44%]\n",
      "Train Ep 9: 100%|██████████| 338/338 [00:11<00:00, 30.37it/s, Loss=0.0061, Acc=98.88%]\n",
      "Train Ep 10: 100%|██████████| 338/338 [00:11<00:00, 30.57it/s, Loss=0.0345, Acc=98.98%]\n",
      "Train Ep 11: 100%|██████████| 338/338 [00:11<00:00, 30.30it/s, Loss=0.0051, Acc=98.92%]\n",
      "Train Ep 12: 100%|██████████| 338/338 [00:11<00:00, 30.44it/s, Loss=0.0065, Acc=99.16%]\n",
      "Train Ep 13: 100%|██████████| 338/338 [00:11<00:00, 30.58it/s, Loss=0.0039, Acc=99.13%]\n",
      "Train Ep 14: 100%|██████████| 338/338 [00:11<00:00, 30.51it/s, Loss=0.1415, Acc=99.25%]\n",
      "Train Ep 15: 100%|██████████| 338/338 [00:11<00:00, 30.43it/s, Loss=0.0002, Acc=99.25%]\n",
      "Train Ep 16: 100%|██████████| 338/338 [00:11<00:00, 30.70it/s, Loss=0.0007, Acc=98.85%]\n",
      "Train Ep 17: 100%|██████████| 338/338 [00:11<00:00, 30.41it/s, Loss=0.0066, Acc=99.14%]\n",
      "Train Ep 18: 100%|██████████| 338/338 [00:11<00:00, 30.43it/s, Loss=0.0187, Acc=99.39%]\n",
      "Train Ep 19: 100%|██████████| 338/338 [00:11<00:00, 30.65it/s, Loss=0.0001, Acc=99.34%]\n",
      "Train Ep 20: 100%|██████████| 338/338 [00:11<00:00, 30.25it/s, Loss=0.0094, Acc=99.44%]\n",
      "Train Ep 21: 100%|██████████| 338/338 [00:11<00:00, 30.51it/s, Loss=0.0038, Acc=99.50%]\n",
      "Train Ep 22: 100%|██████████| 338/338 [00:11<00:00, 30.25it/s, Loss=0.0149, Acc=99.50%]\n",
      "Train Ep 23: 100%|██████████| 338/338 [00:11<00:00, 30.57it/s, Loss=0.0014, Acc=99.31%]\n",
      "Train Ep 24: 100%|██████████| 338/338 [00:11<00:00, 30.60it/s, Loss=0.0001, Acc=99.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training finished for eurosat. Model saved.\n",
      "\n",
      "Running Benchmarks for eurosat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.1 | L-Acc: 88.8% | R-Acc: 84.1% | FPS: 37616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.2 | L-Acc: 94.6% | R-Acc: 93.3% | FPS: 29913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.3 | L-Acc: 96.4% | R-Acc: 95.4% | FPS: 26566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.4 | L-Acc: 97.4% | R-Acc: 96.8% | FPS: 21210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.5 | L-Acc: 97.9% | R-Acc: 97.4% | FPS: 19902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.6 | L-Acc: 98.1% | R-Acc: 97.6% | FPS: 16721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.7 | L-Acc: 98.4% | R-Acc: 98.1% | FPS: 13943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.8 | L-Acc: 98.4% | R-Acc: 98.2% | FPS: 13346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.9 | L-Acc: 98.3% | R-Acc: 98.3% | FPS: 10842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 1.0 | L-Acc: 98.4% | R-Acc: 98.4% | FPS: 9944\n",
      "Finished eurosat. Plots saved.\n",
      "\n",
      "========================================\n",
      "PHASE 2: TRANSFER TO RSSCN7\n",
      "========================================\n",
      ">> No checkpoint found for rsscn7. Training...\n",
      ">> Loaded CIFAR-10 weights (Head re-initialized)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep 0: 100%|██████████| 35/35 [00:01<00:00, 25.84it/s, Loss=0.5101, Acc=60.27%]\n",
      "Train Ep 1: 100%|██████████| 35/35 [00:01<00:00, 25.67it/s, Loss=0.2476, Acc=89.06%]\n",
      "Train Ep 2: 100%|██████████| 35/35 [00:01<00:00, 25.93it/s, Loss=0.2313, Acc=96.03%]\n",
      "Train Ep 3: 100%|██████████| 35/35 [00:01<00:00, 25.67it/s, Loss=0.0242, Acc=99.11%]\n",
      "Train Ep 4: 100%|██████████| 35/35 [00:01<00:00, 26.09it/s, Loss=0.0203, Acc=99.96%] \n",
      "Train Ep 5: 100%|██████████| 35/35 [00:01<00:00, 26.04it/s, Loss=0.2212, Acc=90.40%]\n",
      "Train Ep 6: 100%|██████████| 35/35 [00:01<00:00, 26.04it/s, Loss=0.0867, Acc=95.18%]\n",
      "Train Ep 7: 100%|██████████| 35/35 [00:01<00:00, 26.16it/s, Loss=0.2052, Acc=95.71%]\n",
      "Train Ep 8: 100%|██████████| 35/35 [00:01<00:00, 26.12it/s, Loss=0.0944, Acc=97.54%]\n",
      "Train Ep 9: 100%|██████████| 35/35 [00:01<00:00, 26.33it/s, Loss=0.0607, Acc=97.95%]\n",
      "Train Ep 10: 100%|██████████| 35/35 [00:01<00:00, 26.22it/s, Loss=0.0136, Acc=98.21%]\n",
      "Train Ep 11: 100%|██████████| 35/35 [00:01<00:00, 25.99it/s, Loss=0.0051, Acc=99.38%]\n",
      "Train Ep 12: 100%|██████████| 35/35 [00:01<00:00, 25.84it/s, Loss=0.0062, Acc=99.24%]\n",
      "Train Ep 13: 100%|██████████| 35/35 [00:01<00:00, 25.79it/s, Loss=0.0072, Acc=99.02%]\n",
      "Train Ep 14: 100%|██████████| 35/35 [00:01<00:00, 25.99it/s, Loss=0.0037, Acc=99.82%] \n",
      "Train Ep 15: 100%|██████████| 35/35 [00:01<00:00, 26.03it/s, Loss=0.0088, Acc=99.42%]\n",
      "Train Ep 16: 100%|██████████| 35/35 [00:01<00:00, 25.86it/s, Loss=0.0150, Acc=99.24%]\n",
      "Train Ep 17: 100%|██████████| 35/35 [00:01<00:00, 26.06it/s, Loss=0.0237, Acc=99.51%]\n",
      "Train Ep 18: 100%|██████████| 35/35 [00:01<00:00, 25.95it/s, Loss=0.0610, Acc=99.87%]\n",
      "Train Ep 19: 100%|██████████| 35/35 [00:01<00:00, 25.92it/s, Loss=0.0864, Acc=99.82%]\n",
      "Train Ep 20: 100%|██████████| 35/35 [00:01<00:00, 26.00it/s, Loss=0.0690, Acc=99.91%] \n",
      "Train Ep 21: 100%|██████████| 35/35 [00:01<00:00, 26.31it/s, Loss=0.0282, Acc=99.64%]\n",
      "Train Ep 22: 100%|██████████| 35/35 [00:01<00:00, 26.09it/s, Loss=0.0007, Acc=99.64%]\n",
      "Train Ep 23: 100%|██████████| 35/35 [00:01<00:00, 26.16it/s, Loss=0.0004, Acc=100.00%]\n",
      "Train Ep 24: 100%|██████████| 35/35 [00:01<00:00, 26.06it/s, Loss=0.0048, Acc=99.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training finished for rsscn7. Model saved.\n",
      "\n",
      "Running Benchmarks for rsscn7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.1 | L-Acc: 78.0% | R-Acc: 74.6% | FPS: 37628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.2 | L-Acc: 85.4% | R-Acc: 84.6% | FPS: 30009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.3 | L-Acc: 90.0% | R-Acc: 87.3% | FPS: 26588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.4 | L-Acc: 91.6% | R-Acc: 89.8% | FPS: 21183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.5 | L-Acc: 93.4% | R-Acc: 90.7% | FPS: 19936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.6 | L-Acc: 93.4% | R-Acc: 92.3% | FPS: 16732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.7 | L-Acc: 93.2% | R-Acc: 93.8% | FPS: 13960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.8 | L-Acc: 93.0% | R-Acc: 94.1% | FPS: 13366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 0.9 | L-Acc: 93.6% | R-Acc: 93.4% | FPS: 10859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "m.backbone.blocks.0.attn.attn_drop, m.backbone.blocks.1.attn.attn_drop, m.backbone.blocks.10.attn.attn_drop, m.backbone.blocks.11.attn.attn_drop, m.backbone.blocks.2.attn.attn_drop, m.backbone.blocks.3.attn.attn_drop, m.backbone.blocks.4.attn.attn_drop, m.backbone.blocks.5.attn.attn_drop, m.backbone.blocks.6.attn.attn_drop, m.backbone.blocks.7.attn.attn_drop, m.backbone.blocks.8.attn.attn_drop, m.backbone.blocks.9.attn.attn_drop, m.backbone.head_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ratio 1.0 | L-Acc: 93.8% | R-Acc: 93.8% | FPS: 9947\n",
      "Finished rsscn7. Plots saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Try importing FLOPs counting libraries (for Benchmarking only)\n",
    "# ------------------------------------------------------------------------------\n",
    "try:\n",
    "    from fvcore.nn import FlopCountAnalysis\n",
    "    HAS_FVCORE = True\n",
    "except ImportError:\n",
    "    HAS_FVCORE = False\n",
    "    print(\"Warning: 'fvcore' not found. GFLOPs will be estimated theoretically.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 64,\n",
    "    'resize_dim': 224,\n",
    "    'learning_rate_selector': 1e-4,\n",
    "    'save_path': './saved_models',\n",
    "    'results_path': './benchmarks_results'\n",
    "}\n",
    "\n",
    "DATASET_PATHS = {\n",
    "    'aid': 'AID-data',\n",
    "    'ucmerced': 'UCMerced_LandUse/Images',\n",
    "    'rsscn7': './RSSCN7',\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['save_path'], exist_ok=True)\n",
    "os.makedirs(CONFIG['results_path'], exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# REPRODUCIBILITY SETUP\n",
    "# ------------------------------------------------------------------------------\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # Ensure deterministic behavior in CuDNN (Trade-off: may be slower)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "# Generator for reproducible random_split\n",
    "GEN = torch.Generator()\n",
    "GEN.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Worker init for DataLoaders\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. MODEL ARCHITECTURE\n",
    "# ==============================================================================\n",
    "class ASEL(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Load standard ViT\n",
    "        self.backbone = timm.create_model('vit_tiny_patch16_224', pretrained=pretrained, num_classes=num_classes)\n",
    "        self.embed_dim = self.backbone.embed_dim\n",
    "        \n",
    "        # The \"Selector\" Network\n",
    "        self.patch_selector = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim * 2, 96), \n",
    "            nn.LayerNorm(96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "        # (Added only for Benchmarking Plots: Pre-computed central indices)\n",
    "        H, W = 14, 14\n",
    "        center = (H - 1) / 2.0\n",
    "        y, x = np.ogrid[:H, :W]\n",
    "        dist = (x - center)**2 + (y - center)**2\n",
    "        self.central_indices = torch.from_numpy(np.argsort(dist.flatten())).long()\n",
    "\n",
    "    def _get_patch_embeddings(self, x):\n",
    "        x = self.backbone.patch_embed(x)\n",
    "        x = x + self.backbone.pos_embed[:, 1:]\n",
    "        return x\n",
    "\n",
    "    def _process_transformer(self, x_patches):\n",
    "        B = x_patches.shape[0]\n",
    "        cls_token = self.backbone.cls_token.expand(B, -1, -1) + self.backbone.pos_embed[:, :1]\n",
    "        x = torch.cat((cls_token, x_patches), dim=1)\n",
    "        x = self.backbone.pos_drop(x)\n",
    "        x = self.backbone.blocks(x)\n",
    "        x = self.backbone.norm(x)\n",
    "        return self.backbone.head(x[:, 0])\n",
    "\n",
    "    def _compute_importance_scores(self, x_patches):\n",
    "        global_feat = x_patches.mean(dim=1, keepdim=True).expand(-1, x_patches.shape[1], -1)\n",
    "        selector_input = torch.cat([x_patches, global_feat], dim=-1)\n",
    "        return self.patch_selector(selector_input).squeeze(-1)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # MODE A: TRAINING\n",
    "    # --------------------------------------------------------------------------\n",
    "    def forward_train(self, x_images, k_ratio):\n",
    "        x_patches = self._get_patch_embeddings(x_images)\n",
    "        scores = self._compute_importance_scores(x_patches)\n",
    "        B, N, D = x_patches.shape\n",
    "        k = int(N * k_ratio)\n",
    "        if k < 1: k = 1\n",
    "\n",
    "        _, topk_idx = torch.topk(scores, k, dim=1)\n",
    "        mask_hard = torch.zeros_like(scores)\n",
    "        mask_hard.scatter_(1, topk_idx, 1.0)\n",
    "        \n",
    "        # Straight-Through Estimator\n",
    "        mask = mask_hard - scores.detach() + scores\n",
    "        \n",
    "        x_masked = x_patches * mask.unsqueeze(-1)\n",
    "        logits = self._process_transformer(x_masked)\n",
    "        return logits, scores\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # MODE B: INFERENCE (Adapted for Benchmarking Policies)\n",
    "    # --------------------------------------------------------------------------\n",
    "    def forward_inference(self, x_images, k_ratio, policy='learned'):\n",
    "        x_patches = self._get_patch_embeddings(x_images)\n",
    "        B, N, D = x_patches.shape\n",
    "        k = int(N * k_ratio)\n",
    "        if k < 1: k = 1\n",
    "\n",
    "        # Select indices based on Policy\n",
    "        if policy == 'learned':\n",
    "            scores = self._compute_importance_scores(x_patches)\n",
    "            _, topk_idx = torch.topk(scores, k, dim=1)\n",
    "        elif policy == 'random':\n",
    "            topk_idx = torch.stack([torch.randperm(N)[:k] for _ in range(B)]).to(x_patches.device)\n",
    "        elif policy == 'central':\n",
    "            indices = self.central_indices[:k].to(x_patches.device)\n",
    "            topk_idx = indices.unsqueeze(0).expand(B, -1)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown Policy\")\n",
    "\n",
    "        topk_idx_expanded = topk_idx.unsqueeze(-1).expand(-1, -1, D)\n",
    "        x_kept = torch.gather(x_patches, 1, topk_idx_expanded)\n",
    "        \n",
    "        logits = self._process_transformer(x_kept)\n",
    "        return logits\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TRAINING ENGINE\n",
    "# ==============================================================================\n",
    "def train_epoch(model, loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if epoch < 5:\n",
    "        min_k, max_k = 1.0, 1.0 \n",
    "    else:\n",
    "        min_k, max_k = 0.15, 0.75\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Train Ep {epoch}\", leave=True)\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        current_k = random.uniform(min_k, max_k)\n",
    "        \n",
    "        logits, scores = model.forward_train(imgs, k_ratio=current_k)\n",
    "        \n",
    "        loss_cls = F.cross_entropy(logits, labels)\n",
    "        loss_sparsity = 0.02 * scores.mean()\n",
    "        loss = loss_cls + loss_sparsity\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct += (logits.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"Acc\": f\"{correct/total:.2%}\"})\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. BENCHMARKING SUITE\n",
    "# ==============================================================================\n",
    "class Benchmark:\n",
    "    @staticmethod\n",
    "    def measure_metrics(model, device, k_ratio, policy='learned'):\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "        batch_input = torch.randn(64, 3, 224, 224).to(device) \n",
    "        \n",
    "        class Wrapper(nn.Module):\n",
    "            def __init__(self, m, k, p): super().__init__(); self.m = m; self.k = k; self.p = p\n",
    "            def forward(self, x): return self.m.forward_inference(x, self.k, self.p)\n",
    "        \n",
    "        wrapped_model = Wrapper(model, k_ratio, policy)\n",
    "        \n",
    "        if HAS_FVCORE:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                flops_counter = FlopCountAnalysis(wrapped_model, dummy_input)\n",
    "                flops_counter.unsupported_ops_warnings(False)\n",
    "                gflops = flops_counter.total() / 1e9\n",
    "        else:\n",
    "            gflops = 1.1 * k_ratio \n",
    "            \n",
    "        model.eval()\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ = model.forward_inference(batch_input, k_ratio, policy) # Warmup\n",
    "            start_event.record()\n",
    "            for _ in range(50):\n",
    "                _ = model.forward_inference(batch_input, k_ratio, policy)\n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "        total_time_ms = start_event.elapsed_time(end_event)\n",
    "        latency_ms = total_time_ms / 50\n",
    "        throughput = (64 * 50) / (total_time_ms / 1000)\n",
    "        \n",
    "        return gflops, latency_ms, throughput\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_accuracy(model, loader, device, k_ratio, policy):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                logits = model.forward_inference(imgs, k_ratio=k_ratio, policy=policy)\n",
    "                correct += (logits.argmax(1) == labels).sum().item()\n",
    "                total += imgs.size(0)\n",
    "        return correct / total\n",
    "\n",
    "def run_benchmarks_and_plot(model, test_loader, ds_name, device):\n",
    "    print(f\"\\nRunning Benchmarks for {ds_name}...\")\n",
    "    ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    \n",
    "    res = {\n",
    "        'ratios': ratios,\n",
    "        'acc_learned': [], 'acc_random': [], 'acc_central': [],\n",
    "        'gflops': [], 'thr': [], 'lat': []\n",
    "    }\n",
    "    \n",
    "    full_acc = Benchmark.evaluate_accuracy(model, test_loader, device, 1.0, 'learned')\n",
    "    full_gflops, full_lat, full_thr = Benchmark.measure_metrics(model, device, 1.0)\n",
    "    \n",
    "    for r in ratios:\n",
    "        acc_l = Benchmark.evaluate_accuracy(model, test_loader, device, r, 'learned')\n",
    "        acc_r = Benchmark.evaluate_accuracy(model, test_loader, device, r, 'random')\n",
    "        acc_c = Benchmark.evaluate_accuracy(model, test_loader, device, r, 'central')\n",
    "        gf, lat, thr = Benchmark.measure_metrics(model, device, r, 'learned')\n",
    "        \n",
    "        res['acc_learned'].append(acc_l)\n",
    "        res['acc_random'].append(acc_r)\n",
    "        res['acc_central'].append(acc_c)\n",
    "        res['gflops'].append(gf)\n",
    "        res['thr'].append(thr)\n",
    "        res['lat'].append(lat)\n",
    "        \n",
    "        print(f\" Ratio {r:.1f} | L-Acc: {acc_l:.1%} | R-Acc: {acc_r:.1%} | FPS: {thr:.0f}\")\n",
    "\n",
    "    # PLOTS\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(ratios, [x*100 for x in res['acc_learned']], 'r-o', lw=2, label='Ours (Learned)')\n",
    "    plt.plot(ratios, [x*100 for x in res['acc_central']], 'b--s', alpha=0.7, label='Central')\n",
    "    plt.plot(ratios, [x*100 for x in res['acc_random']], 'k--x', alpha=0.5, label='Random')\n",
    "    plt.scatter([1.0], [full_acc*100], c='k', marker='*', s=200, zorder=10, label='Full ViT')\n",
    "    plt.title(f'{ds_name}: Strategy Comparison')\n",
    "    plt.xlabel('Keep Ratio'); plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True, alpha=0.5); plt.legend()\n",
    "    plt.savefig(f\"{CONFIG['results_path']}/{ds_name}_1_strategies.png\"); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(res['thr'], [x*100 for x in res['acc_learned']], 'g-o', lw=2, label='Ours')\n",
    "    plt.scatter([full_thr], [full_acc*100], c='k', marker='*', s=200, label='Full ViT')\n",
    "    plt.title(f'{ds_name}: Accuracy vs Throughput')\n",
    "    plt.xlabel('Throughput (img/s)'); plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True, alpha=0.5); plt.legend()\n",
    "    plt.savefig(f\"{CONFIG['results_path']}/{ds_name}_2_throughput.png\"); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(ratios, res['gflops'], 'm-o', lw=2, label='Ours')\n",
    "    plt.axhline(y=full_gflops, c='k', ls='--', label='Full ViT')\n",
    "    plt.title(f'{ds_name}: GFLOPs Reduction')\n",
    "    plt.xlabel('Keep Ratio'); plt.ylabel('GFLOPs')\n",
    "    plt.grid(True, alpha=0.5); plt.legend()\n",
    "    plt.savefig(f\"{CONFIG['results_path']}/{ds_name}_3_gflops.png\"); plt.close()\n",
    "\n",
    "    lat_50 = res['lat'][4] # Ratio 0.5\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar(['Full ViT', 'Ours (50%)'], [full_lat, lat_50], color=['gray', 'green'], width=0.5)\n",
    "    plt.title(f'{ds_name}: Batch Latency')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.text(0, full_lat, f\"{full_lat:.1f}ms\", ha='center', va='bottom', fontweight='bold')\n",
    "    plt.text(1, lat_50, f\"{lat_50:.1f}ms\", ha='center', va='bottom', fontweight='bold')\n",
    "    plt.savefig(f\"{CONFIG['results_path']}/{ds_name}_4_latency.png\"); plt.close()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. DATA LOADING (Robust & Deterministic)\n",
    "# ==============================================================================\n",
    "class CleanImageFolder(datasets.ImageFolder):\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) \n",
    "                         if entry.is_dir() and not entry.name.startswith('.'))\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"No classes in {directory}\")\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "def create_loader(dataset, batch_size, shuffle):\n",
    "    # Enforce reproducibility inside the DataLoader\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle, \n",
    "        num_workers=CONFIG['num_workers'], \n",
    "        worker_init_fn=seed_worker,  # Important for worker seeding\n",
    "        generator=GEN if shuffle else None, # Important for shuffle seeding\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "def get_dataset(name):\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((224, 224), interpolation=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    if name == 'cifar10':\n",
    "        ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=tf)\n",
    "        test_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=tf)\n",
    "        return ds, test_ds, 10\n",
    "    elif name == 'eurosat':\n",
    "        ds = datasets.EuroSAT(root='./data', download=True, transform=tf)\n",
    "        train_len = int(0.8 * len(ds))\n",
    "        # Use GEN for deterministic split\n",
    "        train_ds, val_ds = random_split(ds, [train_len, len(ds)-train_len], generator=GEN)\n",
    "        return train_ds, val_ds, 10\n",
    "    else:\n",
    "        path = DATASET_PATHS.get(name)\n",
    "        if not path or not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Path not found: {path}\")\n",
    "        ds = CleanImageFolder(root=path, transform=tf)\n",
    "        train_len = int(0.8 * len(ds))\n",
    "        # Use GEN for deterministic split\n",
    "        train_ds, test_ds = random_split(ds, [train_len, len(ds)-train_len], generator=GEN)\n",
    "        return train_ds, test_ds, len(ds.classes)\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MAIN PIPELINE (With Caching Logic)\n",
    "# ==============================================================================\n",
    "def run():\n",
    "    # ------------------------------------------------------------------\n",
    "    # PHASE 1: WARMUP ON CIFAR-10\n",
    "    # ------------------------------------------------------------------\n",
    "    print(f\"\\n{'='*40}\\nPHASE 1: WARMUP ON CIFAR-10\\n{'='*40}\")\n",
    "    cifar_path = f\"{CONFIG['save_path']}/cifar10_warmup.pth\"\n",
    "    cifar_tr, cifar_te, cifar_n = get_dataset('cifar10')\n",
    "    \n",
    "    # Init Model\n",
    "    model = ASEL(num_classes=cifar_n).to(CONFIG['device'])\n",
    "    \n",
    "    # CHECK: Do we have a saved model?\n",
    "    if os.path.exists(cifar_path):\n",
    "        print(f\">> Found existing checkpoint: {cifar_path}\")\n",
    "        print(\">> Loading model and skipping training...\")\n",
    "        model.load_state_dict(torch.load(cifar_path))\n",
    "    else:\n",
    "        print(\">> No checkpoint found. Starting training...\")\n",
    "        loader_tr = create_loader(cifar_tr, CONFIG['batch_size'], shuffle=True)\n",
    "        \n",
    "        # Optimizer\n",
    "        head_params = list(map(id, model.backbone.head.parameters()))\n",
    "        backbone_params = filter(lambda p: id(p) not in head_params, model.backbone.parameters())\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model.patch_selector.parameters(), 'lr': CONFIG['learning_rate_selector']},\n",
    "            {'params': backbone_params, 'lr': 5e-5},\n",
    "            {'params': model.backbone.head.parameters(), 'lr': 5e-4}\n",
    "        ])\n",
    "        \n",
    "        for ep in range(15):\n",
    "            train_epoch(model, loader_tr, optimizer, ep, CONFIG['device'])\n",
    "        \n",
    "        torch.save(model.state_dict(), cifar_path)\n",
    "        print(\">> Training finished. Model saved.\")\n",
    "\n",
    "    # Always run benchmarks (even if loaded)\n",
    "    loader_te = create_loader(cifar_te, CONFIG['batch_size'], shuffle=False)\n",
    "    run_benchmarks_and_plot(model, loader_te, 'cifar10', CONFIG['device'])\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # PHASE 2: TRANSFER TO TARGET DATASETS\n",
    "    # ------------------------------------------------------------------\n",
    "    targets = ['aid', 'eurosat', 'rsscn7']\n",
    "    \n",
    "    for ds_name in targets:\n",
    "        print(f\"\\n{'='*40}\\nPHASE 2: TRANSFER TO {ds_name.upper()}\\n{'='*40}\")\n",
    "        save_name = f\"{CONFIG['save_path']}/{ds_name}_finetuned.pth\"\n",
    "\n",
    "        try:\n",
    "            train_ds, test_ds, n_cls = get_dataset(ds_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {ds_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        test_loader = create_loader(test_ds, CONFIG['batch_size'], shuffle=False)\n",
    "        model_transfer = ASEL(num_classes=n_cls).to(CONFIG['device'])\n",
    "\n",
    "        # CHECK: Do we have a saved fine-tuned model?\n",
    "        if os.path.exists(save_name):\n",
    "            print(f\">> Found existing checkpoint: {save_name}\")\n",
    "            print(\">> Loading model and skipping training...\")\n",
    "            model_transfer.load_state_dict(torch.load(save_name))\n",
    "        \n",
    "        else:\n",
    "            print(f\">> No checkpoint found for {ds_name}. Training...\")\n",
    "            # Load weights from CIFAR-10 Warmup (Excluding Head)\n",
    "            if not os.path.exists(cifar_path):\n",
    "                raise RuntimeError(\"CIFAR-10 model missing! Cannot transfer learn.\")\n",
    "                \n",
    "            pretrained_dict = torch.load(cifar_path)\n",
    "            model_dict = model_transfer.state_dict()\n",
    "            # Filter head weights\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if 'head' not in k}\n",
    "            model_dict.update(pretrained_dict)\n",
    "            model_transfer.load_state_dict(model_dict)\n",
    "            print(\">> Loaded CIFAR-10 weights (Head re-initialized)\")\n",
    "\n",
    "            train_loader = create_loader(train_ds, CONFIG['batch_size'], shuffle=True)\n",
    "\n",
    "            # Optimizer\n",
    "            head_params = list(map(id, model_transfer.backbone.head.parameters()))\n",
    "            backbone_params = filter(lambda p: id(p) not in head_params, model_transfer.backbone.parameters())\n",
    "            optimizer = optim.Adam([\n",
    "                {'params': model_transfer.patch_selector.parameters(), 'lr': CONFIG['learning_rate_selector']},\n",
    "                {'params': backbone_params, 'lr': 2e-5},\n",
    "                {'params': model_transfer.backbone.head.parameters(), 'lr': 5e-4}\n",
    "            ])\n",
    "            \n",
    "            for ep in range(25):\n",
    "                train_epoch(model_transfer, train_loader, optimizer, ep, CONFIG['device'])\n",
    "            \n",
    "            torch.save(model_transfer.state_dict(), save_name)\n",
    "            print(f\">> Training finished for {ds_name}. Model saved.\")\n",
    "\n",
    "        # Always run benchmarks\n",
    "        run_benchmarks_and_plot(model_transfer, test_loader, ds_name, CONFIG['device'])\n",
    "        print(f\"Finished {ds_name}. Plots saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
